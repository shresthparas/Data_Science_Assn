{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dvu6PCNyqdoC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load datasets\n",
        "customers = pd.read_csv('Customers.csv')\n",
        "products = pd.read_csv('Products.csv')\n",
        "transactions = pd.read_csv('Transactions.csv')\n",
        "\n",
        "# Merge datasets\n",
        "data = transactions.merge(customers, on='CustomerID').merge(products, on='ProductID')\n",
        "\n",
        "# Feature Engineering\n",
        "\n",
        "# Calculate total spending per customer\n",
        "customer_spending = data.groupby('CustomerID')['TotalValue'].sum().reset_index()\n",
        "customer_spending.rename(columns={'TotalValue': 'TotalSpending'}, inplace=True)\n",
        "\n",
        "# Calculate transaction count per customer\n",
        "customer_transactions = data.groupby('CustomerID')['TransactionID'].nunique().reset_index()\n",
        "customer_transactions.rename(columns={'TransactionID': 'TransactionCount'}, inplace=True)\n",
        "\n",
        "# Calculate average transaction value per customer\n",
        "customer_avg_transaction = data.groupby('CustomerID')['TotalValue'].mean().reset_index()\n",
        "customer_avg_transaction.rename(columns={'TotalValue': 'AvgTransactionValue'}, inplace=True)\n",
        "\n",
        "# Calculate preferred product category per customer\n",
        "customer_category = data.groupby(['CustomerID', 'Category'])['Quantity'].sum().reset_index()\n",
        "customer_category = customer_category.loc[customer_category.groupby('CustomerID')['Quantity'].idxmax()]\n",
        "customer_category.rename(columns={'Category': 'PreferredCategory'}, inplace=True)\n",
        "\n",
        "# Merge all features\n",
        "customer_features = customers.merge(customer_spending, on='CustomerID') \\\n",
        "                             .merge(customer_transactions, on='CustomerID') \\\n",
        "                             .merge(customer_avg_transaction, on='CustomerID') \\\n",
        "                             .merge(customer_category[['CustomerID', 'PreferredCategory']], on='CustomerID')\n",
        "\n",
        "# Encode categorical variables\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "encoded_region = pd.DataFrame(encoder.fit_transform(customer_features[['Region']]), columns=encoder.get_feature_names_out(['Region']))\n",
        "encoded_category = pd.DataFrame(encoder.fit_transform(customer_features[['PreferredCategory']]), columns=encoder.get_feature_names_out(['PreferredCategory']))\n",
        "# Combine encoded features with numerical features\n",
        "customer_features = pd.concat([customer_features, encoded_region, encoded_category], axis=1)\n",
        "customer_features.drop(['CustomerName', 'SignupDate', 'Region', 'PreferredCategory'], axis=1, inplace=True)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "normalized_features = scaler.fit_transform(customer_features.drop('CustomerID', axis=1))\n",
        "\n",
        "# Compute similarity matrix\n",
        "similarity_matrix = cosine_similarity(normalized_features)\n",
        "\n",
        "# Create a DataFrame for similarity scores\n",
        "similarity_df = pd.DataFrame(similarity_matrix, index=customer_features['CustomerID'], columns=customer_features['CustomerID'])\n",
        "\n",
        "# Function to get top N similar customers\n",
        "def get_top_n_similar(customers_df, target_customer_id, n=3):\n",
        "    if target_customer_id not in customers_df.index:\n",
        "        return []\n",
        "    similarity_scores = customers_df[target_customer_id].drop(target_customer_id)\n",
        "    top_n_customers = similarity_scores.nlargest(n)\n",
        "    return list(top_n_customers.index), list(top_n_customers.values)\n",
        "\n",
        "# Generate Lookalike.csv\n",
        "lookalike_dict = {}\n",
        "for customer_id in customer_features['CustomerID'].head(20):  # First 20 customers\n",
        "    similar_customers, scores = get_top_n_similar(similarity_df, customer_id)\n",
        "    lookalike_dict[customer_id] = list(zip(similar_customers, scores))\n",
        "\n",
        "# Convert to DataFrame for exporting\n",
        "lookalike_df = pd.DataFrame.from_dict(lookalike_dict, orient='index', columns=['Lookalike1', 'Lookalike2', 'Lookalike3'])\n",
        "lookalike_df.to_csv('Lookalike.csv', index_label='CustomerID')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SxryOv00rb2b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}